{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from urllib.request import urlopen\n",
    "from bs4 import BeautifulSoup, SoupStrainer\n",
    "import httplib2\n",
    "import re\n",
    "import pandas as pd\n",
    "import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#making aliases for youtubers whose user channel ids are hash looking strings\n",
    "PONY_SYNDROME = 'UCT-_4GqC-yLY1xtTHhwY0hA'\n",
    "JAMES_CHARLES = 'UCucot-Zp428OwkyRm2I7v2Q'\n",
    "NYMA_TANG = 'UCroDJPcFCf6DBmHns6Xeb8g'\n",
    "ALYSSA_FOREVER = 'UCNEwha2SIAz3NTtv9G0QPsg'\n",
    "JASMINE_BROWN = 'UCw95JvOs39snnMPkYs-6Sog'\n",
    "\n",
    "\n",
    "#25 youtube handles of bloggers that are white/white-passing (based on my perception)\n",
    "WP_YOUTUBER_NAMES = ['jeffreestar', 'jaclynhill', 'macbby11', 'nikkietutorials', 'laura88lee', 'pixiwoo', 'kandeejohnson', 'zoella280390', 'makeupgeektv', 'stilaBabe09', \n",
    "'shaaanxo', 'ChloeMorello', 'Laurenbeautyy', 'Missglamorazzi', 'AllThatGlitters21', 'Juicystar07', 'MannyMua733', 'GlamLifeGuru', 'CutiePieMarzia', 'KathleenLights',\n",
    "'pixi2woo', 'CarliBel55', 'HauteBrilliance', 'SierraMarieMakeup']\n",
    "\n",
    "#25 youtube handles og bloggers that are disenfranchised in beauty community/darker skinned (based on my perception)\n",
    "DK_YOUTUBER_NAMES = ['iamkareno', 'theepatrickstarrr', 'wwwengie', 'bubzbeauty', 'itsalissaweekly', 'mylifeaseva', 'Dope2111', PONY_SYNDROME, 'MichellePhan', 'itsmyRayeRaye', \n",
    "'BritPopPrincess', 'DulceCandy87', 'AndreasChoice', 'macbarbie07', 'ThatsHeart', 'SmartistaBeauty', NYMA_TANG, 'beautycrush', ALYSSA_FOREVER, JASMINE_BROWN, 'Cydbeats', \n",
    "'Irishcel507', 'clothesencounters', 'TTLYTEALA', 'makeupbytinayong']\n",
    "\n",
    "\n",
    "for name in WP_YOUTUBER_NAMES:\n",
    "    youtube = \"https://www.youtube.com/user/{}/videos?sort=p&view=0&flow=grid\".format(name)\n",
    "    print(youtube)\n",
    "    page = urlopen(youtube).read()\n",
    "    soup = BeautifulSoup(page,'html.parser')\n",
    "    soup.prettify()\n",
    "    \n",
    "    #initialize empty list of links\n",
    "    links = []\n",
    "\n",
    "    #pulls links that belong to a particular class\n",
    "    results = soup.find_all('a',{'class':'yt-uix-sessionlink'})\n",
    "    for link in results:\n",
    "        # find the url\n",
    "        url = link.get(\"href\")\n",
    "    \n",
    "        #deletes links that are not channel video links\n",
    "        if \"/watch?v=\" not in url:\n",
    "            continue\n",
    "        else:\n",
    "            links.append(url)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "data = {'top_videos': links, 'channel': 'itsalissaweekly'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data)\n",
    "\n",
    "#displays the top 10 popular videos\n",
    "pd.options.display.max_rows = 10\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "'''\n",
    "script for parsing through youtube video links to get video attributes\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "\n",
    "# for testing\n",
    "SAMPLE_YOUTUBE_NAMES = []\n",
    "\n",
    "for _ in range(0, 10):\n",
    "\tSAMPLE_YOUTUBE_NAMES.append(random.choice(DK_YOUTUBER_NAMES + WP_YOUTUBER_NAMES))\n",
    "\n",
    "print(SAMPLE_YOUTUBE_NAMES)\n",
    "\n",
    "#INDIVIDUAL YOUTUBE LINK PARSING\n",
    "\n",
    "youtube_path = \"https://www.youtube.com/watch?time_continue=1&v=IlCmIBMPhp8\" \n",
    "page = urlopen(youtube_path)\n",
    "soup = BeautifulSoup(page, 'lxml')\n",
    "soup.prettify()\n",
    "#parses through webpage and cleans data to find view count of video\n",
    "un_views_count = str(soup.find('div', class_=\"watch-view-count\"))\n",
    "views_count = re.sub('[^0-9]','', un_views_count)\n",
    "views_count = re.sub(',', '', views_count)\n",
    "\n",
    "#parses through webpage and cleans data to get dislike counts\n",
    "un_dislike_count = str(soup.find('button', title=\"I dislike this\", type=\"button\"))\n",
    "dislike_count =  re.sub('[^0-9,]',' ', un_dislike_count)\n",
    "dislike_count = re.sub(',', '', dislike_count).split()\n",
    "#del dislike_count[1]\n",
    "\n",
    "\n",
    "#parses through webpage and cleans data to get likes counts\n",
    "un_likes_amount = str(soup.find('button', title=\"I like this\", type='button'))\n",
    "likes_count =  re.sub('[^0-9,]',' ', un_likes_amount)\n",
    "likes_count = re.sub(',', '', likes_count).split()\n",
    "#del likes_count[1]\n",
    "\n",
    "print(\"dislikes:\", int(dislike_count[0]))\n",
    "print(\"likes:\", int(likes_count[0]))\n",
    "print('views:', views_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
